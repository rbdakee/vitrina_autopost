## Проект: Vitrina Autopost

Сервис для **автоматического постинга видео** из Google Drive в соцсети через `upload-post.com`.  
Данные о постах и пользователях берутся из Google Sheets, видео уникализируется под каждого пользователя с помощью `ffmpeg` и отправляется в API.

---

## Основная логика

- **Источник постов**: Google Sheets (`SHEET_POSTS`), каждая строка — один пост.
- **Файлы**:
  - `auto_post.py` — основной скрипт:
    - читает настройки из `.env`;
    - ходит в Google Sheets (`posts`, `setup`, `history_posts`);
    - по ссылке/ID из `drive_file_link` скачивает видео из Google Drive;
    - для каждого `user` из листа `setup`:
      - при необходимости уникализирует видео через `unique.py`;
      - загружает ролик в `upload-post.com` для всех отмеченных платформ (Instagram, TikTok и т.п.);
    - пишет результат в лист `history_posts` и в колонки `status` / `result` исходного поста.
  - `unique.py` — библиотека уникализации видео:
    - меняет скорость, цвет, резкость;
    - опционально добавляет логотип и текст;
    - модифицирует аудио (громкость, фильтры, питч);
    - использует `ffmpeg` и, при наличии, фильтр `rubberband`.
- **Режим работы**:
  - контейнер стартует, выполняет один прогон `auto_post.py`;
  - далее `cron` запускает задачу по расписанию (по умолчанию — раз в час из `crontab.txt`).

---

## Структура проекта

- `auto_post.py` — основной сценарий автопостинга.
- `unique.py` — модуль уникализации видео (ffmpeg).
- `Dockerfile` — образ приложения (Python + cron + ffmpeg).
- `entrypoint.sh` — точка входа контейнера, настраивает окружение и cron.
- `crontab.txt` — cron-расписание для запуска `run_job.sh`.
- `requirements.txt` — Python-зависимости.
- `.env` — переменные окружения (секреты, ID таблиц и параметры работы).

---

## Настройка окружения разработчика

### 1. Системные зависимости

- **Python**: 3.11+
- **FFmpeg**: обязателен (для `unique.py`):
  - Linux: через пакетный менеджер (`apt install ffmpeg` и т.п.);
  - Windows: установить ffmpeg и добавить `ffmpeg`/`ffprobe` в `PATH`.
- (Опционально) фильтр `rubberband`:
  - если не установлен, код автоматически делает повторную попытку без него.

### 2. Установка python-зависимостей

```bash
pip install -r requirements.txt
```

### 3. Переменные окружения (`.env`)

**Важно:** реальный файл `.env` с секретами **не должен попадать в git**.  
Рекомендуется создать `.env.example` без ключей, а `.env` держать локально/в Secret Manager.

Ключевые переменные:

- **Интеграция с upload-post.com**
  - `UPLOAD_POST_API_KEY` — API-ключ для сервиса.
  - `UPLOAD_POST_ENDPOINT` — (опционально) URL эндпоинта, по умолчанию `https://api.upload-post.com/api/upload`.
- **Google API**
  - `GOOGLE_SERVICE_ACCOUNT_JSON` — путь к JSON-файлу сервисного аккаунта **или** сам JSON (одной строкой).
  - `SPREADSHEET_ID` — ID Google Sheets с постами и настройками.
- **Названия листов** (можно оставить по умолчанию):
  - `SHEET_POSTS` — лист с постами (по умолчанию `posts`).
  - `SHEET_SETUP` — лист с пользователями и платформами (`setup`).
  - `SHEET_HISTORY` — лист истории публикаций (`history_posts`).
- **Параметры обработки**
  - `PROCESSING_STALE_MINUTES` — через сколько минут запись со статусом `processing` считается «зависшей» и может быть переработана.
  - `MAX_POSTS_PER_RUN` — ограничение количества постов за один прогон (число или пусто для «без лимита»).
  - `TEST_RUN` — `TRUE`/`FALSE`; при `TRUE`:
    - не идёт в Google Drive;
    - не вызывает `upload-post.com`;
    - работает в «сухом» режиме.
  - `ENABLE_UNIQUE` — `TRUE`/`FALSE`; включает/выключает уникализацию.
  - `UNIQUE_LOGO_PATH` — путь к логотипу (png/jpg) для наложения.
  - `UNIQUE_OVERLAY_TEXT` — текст-оверлей на видео.
  - `UPLOAD_TIMEOUT` — таймаут HTTP-запроса к `upload-post.com` (секунды).

---

## Формат Google Sheets

### Лист `posts`

Ожидаемые колонки (регистр не критичен, используются нормализованные имена):

- `caption` — подпись к видео.
- `drive_file_link` — ссылка или ID файла в Google Drive.
- `to_post` — флаг (`TRUE`/`FALSE`), нужно ли обрабатывать строку.
- `status` — статус обработки (`processing`, `posted`, `failed`, `partial` и т.п.).
- `result` — текстовый результат / краткая сводка (обновляется скриптом).

Рабочий цикл для строки:

1. `to_post = TRUE`, `status` пустой или не `posted`.
2. Скрипт ставит `status = processing`, `result = "processing since <ts>"`.
3. После завершения:
   - `status = posted` / `partial` / `failed`;
   - `result = "ok=X fail=Y | ..."`;
   - `to_post = FALSE`.

### Лист `setup`

Колонки:

- `users` — имя/идентификатор пользователя (строка).
- `instagram` / `tiktok` / ... — булевы колонки: если значение `TRUE`, для этого пользователя нужно постить в данную платформу.

Скрипт формирует структуру `{user: [platform1, platform2, ...]}`.

### Лист `history_posts`

Исторический лог: каждая запись — попытка публикации на конкретную платформу.

Колонки (инициализируются автоматически при первом запуске):

- `ts` — время события.
- `post_row` — номер строки из листа `posts`.
- `user` — пользователь.
- `platform` — платформа.
- `caption` — подпись.
- `drive_file_id` — ID файла в Google Drive.
- `status` — `posted` / `failed`.
- `result` — JSON-ответ сервиса или текст ошибки.

---

## Запуск локально (для отладки)

1. Заполнить `.env` (без выкладывания в репозиторий).
2. Убедиться, что `ffmpeg`/`ffprobe` в `PATH`.
3. Запустить:

```bash
python auto_post.py
```

Рекомендуется сначала запускать с:

- `TEST_RUN=TRUE`;
- `MAX_POSTS_PER_RUN=1`;
- небольшим числом строк в листе `posts`.

---

## Запуск в Docker

### Билд и запуск

```bash
docker compose build
docker compose up -d
```

Контейнер:

- использует образ `python:3.11-slim`;
- устанавливает `cron`, `ffmpeg`, зависимости из `requirements.txt`;
- копирует `auto_post.py`, `unique.py`, `crontab.txt`, `entrypoint.sh`;
- монтирует:
  - `./credentials.json` в `/app/sa.json` (service account для Google);
- подхватывает переменные окружения из `.env`.

`entrypoint.sh`:

- собирает всё окружение контейнера в `/etc/profile.d/container_env.sh`, чтобы его видел `cron`;
- регистрирует cron-таб (`crontab /etc/cron.d/app-crontab`);
- **один раз** запускает `auto_post.py` сразу при старте;
- стартует службу `cron` и выводит лог `/var/log/cron.log`.

`crontab.txt` по умолчанию содержит задачу:

```text
0 * * * * root /usr/local/bin/run_job.sh >> /var/log/cron.log 2>&1
```

То есть `auto_post.py` запускается раз в час.  
Для изменения расписания достаточно поправить `crontab.txt` и пересобрать образ.

---

## Заметки для DevOps / инфраструктуры

### Ресурсы и требования

- **CPU**:
  - уникализация видео через `ffmpeg` ресурсоёмкая (scale, crop, eq, возможный `rubberband`);
  - рекомендуется минимум **2 vCPU**, лучше 4+ при больших объёмах.
- **Память**:
  - Python + ffmpeg + буферы, без загрузки всего ролика в память;
  - ориентир: **1–2 ГБ RAM** на контейнер для коротких роликов; больше при высоком параллелизме или длинных видео.
- **Диск**:
  - временные файлы в `tempfile` и внутри контейнера;
  - размер: минимум 2–3× максимального размера исходного видео на прогон (учитывая уникализированные копии на пользователя);
  - при больших объёмах стоит:
    - перенести tmp в отдельный volume или быстрый диск;
    - мониторить заполнение диска и чистку `/tmp`/`/var/tmp`.
- **Сеть**:
  - ingress: загрузка видео из Google Drive;
  - egress: загрузка в `upload-post.com`;
  - важно иметь стабильный канал, особенно если файлы несколько сотен МБ.

### Масштабирование и отказоустойчивость

- Базовая логика рассчитана на **одиночный экземпляр**:
  - скрипт работает поверх одной таблицы Google Sheets и меток `to_post`/`status`.
  - при запуске нескольких контейнеров без доп. координации возможны гонки:
    - два экземпляра заберут одну и ту же строку до того, как она станет `processing`.
- Варианты:
  - либо держать **один контейнер** на таблицу;
  - либо реализовать внешний механизм блокировок/шардинга (отдельные таблицы/листы или колонка-«owner»).

### Мониторинг и логирование

- **Внутри контейнера**:
  - основной лог — `/var/log/cron.log` (stdout/err от `auto_post.py`);
  - логи удобно забирать через docker-лог-драйвер (json-file, fluentd, Loki и т.п.).
- **На уровне приложения**:
  - часть технических ошибок и бизнес-результатов уходит в лист `history_posts`;
  - можно строить простую статистику (ок/ошибки, платформы, пользователи).
- Рекомендуется:
  - добавить алерты по:
    - частоте `failed` в листе `history_posts`;
    - появлению «старых» строк со статусом `processing` дольше `PROCESSING_STALE_MINUTES`.

### Безопасность и секреты

- Никогда не хранить реальный `.env` и `credentials.json` в репозитории.
- Для продакшена:
  - использовать Secret Manager / Vault / Kubernetes Secrets;
  - монтировать `credentials.json` в контейнер только для чтения (как сейчас: `:ro`);
  - ограничить IAM у сервисного аккаунта только нужными правами:
    - чтение Google Drive (readonly);
    - доступ к нужной Google Sheets.

### Типовой прод-сценарий

- Один контейнер на проект/Google Sheets.
- Cron-интервал подбирается исходя из SLA (например, каждые 5–15 минут).
- `MAX_POSTS_PER_RUN` ограничивает «волну» постов, чтобы не перегружать API.
- `PROCESSING_STALE_MINUTES` чуть больше максимальной ожидаемой длительности прогона.

---

## Что ещё можно улучшить

- **Конфигурация**:
  - вынести часть параметров (`SHEET_*`, интервалы и т.п.) в конфиг-файл (YAML/JSON), чтобы не плодить переменные окружения.
- **Метрики**:
  - добавить экспозицию метрик (Prometheus или простые JSON-эндпоинты) для количества успешных/ошибочных постов, времени обработки и т.п.
- **Логи**:
  - унифицировать формат логов (JSON-строки с полями `ts`, `level`, `event`, `row_id`, `user`, `platform`).
- **Тестирование**:
  - добавить unit-тесты для парсинга Google Sheets и для функций из `unique.py` (конфигурация ffmpeg без фактического запуска).

